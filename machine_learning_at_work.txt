<Machine learning at work 머신러닝 실무 프로젝트 - 아리가 미치아키 - 한빛미디어>

* 모델:
  - 인풋데이터, 아웃풋 데이터 사이에 드러나지 않은 관계를
  수식, 규칙으로 근사한것
  - 알고리즘과 파라미터로 구성됨

* 인풋데이터 : 주로 벡터화(여러가지 데이터를 한 배열에 넣은 모양)

* 머신러닝 프로젝트 과정 (대체로):
  1. 문제 정의 - 목적이 무엇인지 명확히!
  2. 머신러닝을 사용하지 않는 방법 없는지 검토!!! - 기술부채(출시를 서두르기 위해 해결하지 못한 문제, 어설픈 설계, 문서화, 컴파일러 경고 등) 쉽게 누적 때문
    : 해결하려는 문제를 머신러닝 문제로 바꾸기

  3. 머신러닝 시스템을 설계
  4. 사용할 알고리즘 선택
  5. 특징과 정답 데이터, 로그를 설계 ???
  6. 데이터 수집과 전처리
    : 문제 풀기 위한 도구 선택 및 전처리

  7. 학습 수행, 파라미터 튜닝
    : 모델 구축

  8. 시스템에 통합
    : 기존 서비스에 통합

* 해결하려는 문제 자체가 사람도 하기 어려운 일이라면 머신러닝으로 해결하는 것 역시 어렵다
  (특히 지도학습, 정답이 무엇인지 사람이 기계에게 알려줘야함)


* 머신러닝 문제 해결 사례 핵심
  - 알고리즘: 어떤 알고리즘 사용?
  - 데이터특징: 어떤 데이터를 특징으로 사용?
  - 통합: 머신러닝 부분 어떻게 통합?

* 머신러닝으로 해결 가능한가? 아닌가? 구분!
  모델 구현하는 일(데이터 분석의 80%는 전처리)
  머신러닝 시스템 개발은 시행착오를 반복하는 과정
  4~7번 반복, 그러므로 시행착오 효율적으로 하는 것 중요



=========================================
<Chapter 1 : 머신러닝 프로젝트 시작하기>

<머신러닝 시스템 프로젝트 과정>

@1. 문제 정의 - 목적이 무엇인지 명확히!

@2. 머신러닝을 사용하지 않는 방법 없는지 검토!!!

    - 기술부채(출시를 서두르기 위해 해결하지 못한 문제, 어설픈 설계, 문서화, 컴파일러 경고 등) 쉽게 누적 때문

    오랜 운용 > 사용자 경향 변함 > 입력 경향 바뀜 (데이터 옥동자라는 의미 변화 예시)
    그러므로 데이터 모델도 갱신(유지보수 필요)

    애초에 머신러닝은 대량 데이터 처리에 사용되므로
    생각하지 못한 예측 결과 출력 위험 항상 존재
    (구글 포토 : 흑인을 고릴라로 인식 > 인종차별 문제 사례)

    * 2가지 조건 만족 할때 머신러닝 적용 하면 좋음
      1. 대량의 데이터에 대해 고속으로 안정된 판단 내려야한다
      2. 예측 결과에 일정 수준 오류가 용인 된다 : 예측이 100% 정확하지 않음 > 운영 쪽에서 이 오류 대응할 구조 꼭 필요
        (의도치 않은 예측결과 나오면 사후 개입하는: 고릴라같은 아웃풋은 삭제하는 룰베이스 예외처리!)

    * 최소기능제품 만들기 (MVP : minimum viable product) == 가설 검증
      : 처음 세운 가설 맞는지 미리 검증! (모델 구현 테스트 후 목표자체가 틀릴수도 있으니까)


@3. 머신러닝 시스템을 설계

    * 핵심
    1. 예측결과 어떻게 이용 : 배치 후 디비저장(따로 새벽에 모델 돌려서 예측값 얻어놓기) /혹은/ 실시간 비동기로 활용(유저 액션에 따라 바로바로 예측하기)
    2. 예측 오류의 영향을 어떻게 흡수 : 예측후 사람이 사후 체크 프로세스 만들기! /혹은/ 잘못된예측이 큰 영향 없을때 사용

    * 구체적인 목표 성능과 포기 지점 설정하기
    - 없으면 전처리 하면서 데이터 도메인 지식 생겨서... 근거없는 자신감으로 성능 계속 더 개선할 수있다는 착각의 늪 빠짐 > 매몰비용 높아짐
    (2개월 안에 90% 성능! 과같이 구체적으로 계획하기)


@4. 사용할 알고리즘 선택

    - 데이터 특성을 아느냐 : 정답을 안다면(지도학습) : 모른다면 군집화같은(비지도학습) 혹은 데이터 시각화를 통해 특징 알아내기
    - 데이터 양 : 온라인 학습 /혹은/ 배치 학습

@5. 특징과 정답 데이터, (로그를 설계: 어플리케이션 case)

    - 피쳐(특징): 어떤 피쳐를 사용할 것인가? : 도메인 전문가 협조 필요
    - 범주형 변수를 > dummy더미 변수로(원핫인코딩, 0,1수치데이터화)
    - numeric(수치형)변수는 그대로 사용 가능

    고전 머신러닝은 어떤 피쳐 선택하느냐가 핵심이었음 > 딥러닝에선 피쳐보단 신경망 구조가 핵심

    - 데이터 레이블링(정답지 만들기)
    - 웹 어플리케이션의 로그로 정답 데이터 만듬 (어떤 페이지 클릭! 광고 효과 예시)
    (로그 설계시 생각나는 특징 모두 포함 시켜야함! 로그 수집 한번 시작하면 바꾸기 어려움, 바꿔도 그전 데이터 사용 못하게됨)


@6. 데이터 수집과 전처리
    - 정상범주 넘어간 이상값 처리
    - 값의 변동폭으로 인한 영향 줄이는 정규화
    - 범주형데이터 > 수치형데이터로 변환
    등등


@7. 학습 수행, 파라미터 튜닝
    - 하이퍼 파라미터 조정하며 > 시행착오 거치기 > 더 나은 성능 찾기 (예측한 성능 기준치를 넘는 것을 목표로 하기! 목표없는성능개선X!)

    *(처음 작성한 코드가 오류없이 작동할때 느끼는 불안감 == 첫번째 예측모델에서 99% 성능이 나올때): 뭔가 의심해야함
    - 과적합 (학습데이터에만 적합, 새 데이터는 예측 못함) <=> 일반화 generalization(처음보는 데이터 처리 잘함)
    - 학습데이터에 테스트데이터 섞이는 (데이터 유출 data leakage)
    일 수 있음

    * 오답낸 예측 결과를 살펴봄 > 원인 무엇인지? 오답 공통점 없는지?
    (만약, 결과 계속 안좋다면 4단계 알고리즘 검토부터 다시)

    * 과적합 방지
    1. 교차검증 cross validation : 학습데이터를 training훈련, validation검증 (9:1)로 나눠서
      검증데이터로 성능을 그때그때 측정해가며 학습시키기

    (- 학습데이터 = (트레이닝데이터 + 검증데이터)
    - 총 데이터 = 학습데이터 + 테스트데이터)

    2. 규제화 regularization : 약간 성능 낮춰서 더 일반화 시키기 (드랍아웃처럼)
    3. 학습곡선 살피기 : learning curve



@8. 시스템에 통합
    - 예측 성능이 > 비즈니스 성과(목표) 달성하는 지 여부 모니터링
    - 데이터 경향 변함 > 그러므로 모델도 꾸준히 개선 필요 (시스템 통합하면 끝 X)
====================
<머신러닝 시스템 문제 대처>

* 머신러닝 시스템 운영 문제
A. 확률적인 부분 있어서 자동 테스트 어려움
B. 오래 운용하면 사용자 경향 변해서 입력 경향도 변함
C. 처리 파이프라인이 복잡해짐
D. 데이터 의존 관계가 복잡헤짐
E. 실험 코드 혹은 파라미터가 포함되기 쉬움
F. 개발 시스템과 운영 시스템 간의 언어/프레임워크가 제각기이기 쉽다

* 문제 대처법
1. 황금기준을 사용한 예측 성능 모니터링 (A, B, D) : 예측 성능에 임계값 알림 설정하기(일정성능 안나오면 알람)
2. 예측 모델 모듈화, 모델에 대한 A/B 테스트 실시 (B) : 예측 모델 병렬로 두고 바꿔가며 성능 테스트
3. 모델 버전관리 > 원하는 모델로 돌아가기 가능하도록 (D, E) : 자유로운 롤백 (소스코드, 모델, 데이터 모두 버전관리 하기)
4. 데이터 처리 파이프라인 자체를 저장 (C, E) : 전처리 과정 코드도 모델과 함께 저장하기 (자연어처리시 단어 분절, 단어 빈도 측정의 전처리 단계에서도 파라미터튜닝이 존재하기 때문)
5. 개발 시스템과 운영 시스템 간의 언어/프레임워크 일치시키기 (F) : 파이썬 텐서플로우 모델 + 파이썬 장고 웹 프레임워크, 그래야 마이그레이션과 커뮤니케이션 비용 줄임 /혹은/ REST API서버화(마이크로 서비스)

* 딥러닝 부상 전의 머신러닝 사실상 표준은 : 사이킷런

=================

<머신러닝 시스템 성공적 운영>

* 일반 시스템 개발과는 달리
머신러닝 시스템은 개발해도 결과물이 안나올수도 있음!!!
(ㅋㅋㅋ 삼성해커톤 소음예측모델개발 경험 ㅋㅋㅋ 어려우면 다른 방식으로라도 만드는 웹어플개발과 다름... 모델 학습이 안되면 쓸수가 없고 다른방법이 없음)

* 키 리소스(인력)
  1. 도메인 전문가 (도메인)
  2. 통계(수학), 머신러닝 전문가 (데이터 사이언티스트) : 문제 설정하는 의사소통 능력 필수
  3. 데이터 분석 인프라 구축 가능한 엔지니어 (컴퓨터 사이언스)
  4. 실패에 대한 위험을 짊어질 수 있는 책임자 : 머신러닝 프로젝트는 실패 확률이 높은 투자임! 머신러닝으로 가치를 얻기를 설득할수 있는 사람! 실무자가 실무에 집중할수있게!
  (4번은 처음 알았다!!!)


===================
<정리 >
< 머신러닝 프로젝트 진행할때는 >
1. MVP로 개념 검증 최우선
2. 머신러닝 이외 해결 방법 꼭 찾아보기!!!
3. 머신러닝에 적합한 문제인지 파악
4. 예측 성능 과 비즈니스 성과!!! 모두 충족시키는지 모니터링


===================
내 머신러인 프로젝트 실패 경험이 정말 값진거였다는걸 깨달았다
1. 후후앤컴퍼니 스팸지수예측 프로젝트와
2. 삼성AI해커톤 소음예측 노이즈캔슬링 프로젝트
모두 머신러닝 만능설 같은 내 고정관념을 깨주었고
웹어플 개발과는 다르게 결과물이 안나올수도 있다는 걸 알려줬고
무엇보다 성능이 먼저 검증이 안되면 시작하면 안된다는 교훈을 주었다
머신러닝 시스템 자체가 실패 가능성이 높은 시스템이라는 사실!!!
===================


=========================================
<Chapter 2 : 머신러닝으로 해결가능한 문제>

<머신러닝 알고리즘 종류>
1. 분류 : 정답이 카테고리
2. 회귀 : 정답이 수치
3. 군집화 : 데이터 그룹화
4. 차원 축소 : 시각화 /혹은/ 계산량 절감
5. 그 외 :
  - 추천
  - 이상 탐지 : 평소와 다른 행동 검출
  - 고빈도 패턴 마이닝 : 발생 빈도 높은 패턴 추출 (기저기와 맥주 사례)
  - 강화학습 : 정답 불명확 환경에서 취할 행동 선택


* 알고리즘 선택 프로세스
데이터가 충분한가(수집) > 범주를 예측하는가(수치 예측) > 정답에 레이블이 있는가(없는가) >

==================지도학습===================
* 분류:
  - 퍼셉트론
  - 로지스틱 회귀
  - 서포트 벡터 머신(SVM)
  - 신경망
  - K-NN(최근접이웃)
  - 결정트리
  - 랜덤포레스트
  - 경사부스팅 결정트리(GBDT)

  그외)
  - 나이브 베이즈 Naive Bayes : 텍스트분류에 사용
  - HMM 히든 마코프 모델 : 음성인식에서 사용

<참고 사항>
  *온라인 학습 : 최적화 하는 방식이 데이터를 하나씩 입력 : 예) 퍼셉트론
   배치 학습  : 최적화 하는 방식이 데이터를 한꺼번에 입력

  *선형분리 (linearly separable) : 무조건 직선으로 나눠짐(직선이 아니라 곡선이라면 X)

  *계단함수step function : 옛날에 쓰던 활성함수 (입력값을 +1 또는 -1로만 바꿔줌)

<퍼셉트론 특성>
    온라인 학습방식
    예측 성능 보통, 학습 빠름
    과적합되기 쉬움
    선형분리 가능한 문제만 풀수있음

    hinge loss 힌지 손실 사용 (렐루 반대모양 )
    SGD stochastic gradient descent 확률적경사하강법 을 사용해 W가중치백터(파라미터) 최적화 함
    활성함수로 계단함수 사용

<로지스틱 회귀>
    출력뿐만 아니라 출력값에 해당하는 속할 '확률'을 계산 가능
    온라인 학습, 배치 학습 모두 가능
    예측 성능 보통, 학습 속도 빠름
    과적합 방지하는 규제항 추가되어있음
    결정경계가 직선이기 때문에 선형 분리 가능한 문제만 풀수있음

    활성함수로 sigmoid, cross-entropy error function 사용

<서포트벡터머신>
    선형분리가 불가능하는 문제에도 적용가능
    마진 최대화를 통해 매끈한 초평면을 학습할 수 있다
    커널이라는 방법을 이용하여 비선형 데이터를 분리할수있다
    선형 커널로는 차원수가 높은 희소sparse 데이터도 학습할수있다
    배치 학습과 온라인 학습에 모두 적용할 수 있다

    * 서포트벡터 : 초평면으로부터(두 집단 경계) 가장 가까운 각 클래스의 데이터
    힌지 손실 가로축 교점이 다름 (0이 아니고 y = 1이 교점)
    이것 때문에 결정경계에 아슬아슬하게 걸처 정답이 된 데이터도 약하게 패널티가 부가되어 결정경계에 마진이 생김
    마진 최대화 생김

    * 두가지 특성
    이렇게 마진 최대화가 : 과적합 억제효과 생김
    커널 기법 : 선형분리가 불가능한 데이터 차원수를 늘려서 선형분리가 가능하게 만듬

    선형커널, 다항식 커널, RBF커널, 등 존재

<신경망>
    다층퍼셉트론

    비선형 데이터를 분리 가능(퍼셉트론과 차이)
    학습 시간이 오래 걸림(GPU기술 발전으로 해결)
    파라미터 수가 많으므로 과적합을 일으키기 쉬움
    가중치의 초기값에 민감하여, 로컬 최적점에 빠지기 쉬움

    softmax함수 사용
    활성함수로 ReLU 함수 사용
    학습에 backpropagation 사용

<k-NN>
    새로 입력된 데이터 > 가장 가까운 k개의 데이터 선택 > k개의 데이터의 다수결 결정(3개 선택중 AAB 라면 A가 2개로 더 많으니까 새 데이터도 A로 판별)

    데이터를 하나씩 순차적으로 학습
    기본적으로 모든 데이터와의 거리를 계산해야 하므로 예측 시간이 걸린다
    k값에 따라 편차는 있지만 예측 성능은 쵄찮은 편이다
    정규화를 통해 피처들끼리의 스케일을 맞출필요가 있다(피처 (예:x,y)축마다 스케일 차이가 있으면 학습이 제대로 되지 않음)

    거리는 유클리드 거리, 마할라노비스 거리를 사용하기도 한다

<결정트리, 랜덤포레스트, GBDT>
    (특성)
    학습한 모델을 사람이 해석하기 쉽다(시각화하여)
    입력 데이터를 정규화할 필요가 없다
    범주형 변수나 데이터의 누락값(계측 오류 등으로 값이 존재하지 않는 경우)이 있어도 용인된다.
    특정 조건이 맞으면 과적합을 일으키는 경향이 있다. (트리가 깊어질수록 학습에 사용되는 데이터 수가 적어져서 과적합 일어나기 쉬움 >> pruning 가지치기로 어느정도 방지 가능)
    비선형 문제에는 적용할 수 있지만, 선형 분리 문제는 잘 풀지 못한다.
    데이터 분포가 특정 클래스로 쏠려 있으면 잘 풀지 못한다
    데이터의 작은 변화에도 결과가 크게 바뀌기 쉽다.
    예측 성능은 보통이다.
    배치 학습으로만 학습할 수 있다.
    학습 결과가 IF-THEN 형태의 규칙이 됨

    피쳐가 많아도 과적합을 일으키기 쉬우므로 미리 차원 축소하거나 특징 선별해줄것

    결정트리 응용 기법 (앙상블 기법 : 여러 학습 결과를 조합하는 기법)
    - 랜덤포레스트 : 결정트리를 위한 피쳐들 조합 몇가지 마련 > 성능 좋았던 몇개의 학습기가 내린 예측 결과를 다수결로 통합
              각각의 트리가 독립적으로 학습 = 학습과정 병렬화
    - GBDT : 표본추출한 데이터를 이용해 순차적으로 얕은 트리를 학습해가는(직렬화) 알고리즘
            예측값과 실제값의 오차를 목표변수로 삼는 방법으로 약점 보안
            학습이 순차적으로 이루어지기때문에 랜덤포레스트보다 학습 시간 오래걸림고 파라미터수 많음
            (ex: XGBoost, LightGBM)

* 회귀 : 지도학습의 한 갈래, 연속된 값(수치) 예측
    - 선형 회귀, : 데이터를 직선으로 근사
    - 다항식 회귀 : 데이터를 곡선으로 근사
    - 라쏘 회귀, : L1규제(학습가중치 절대값)를 규제항으로 사용
    - 릿지 회귀, : L2규제(학습가중치 제곱)를 규제항으로 사용
    - 일래스틱넷 : 선형 회귀에 두가지 규제항 추가
    - 회귀 트리 : 결정트리에에 기초한 회귀 기법 (비선형 데이터 근사 가능)
    - SVR (support vector regression) : SVM에 기초한 회귀 기법 (비선형 데이터 근사 가능)

<선형회귀 원리>
  퍼셉트론 구조에서 활성함수 부분을 없앤것 = (수치를 바로 출력)

==================비지도학습===================
* 군집화
  데이터의 경향성 파악하는데 사용하는 기법
  - 계층적 군집화 hierarchical clustering
  - k-means : k개의 그룹으로 나누는 기법

* 차원축소 dimension reduction
  정보를 가능한 온전히 보존하면서 고차원 데이터를 저차원 데이터로 변환하는 기법
  (ex: 100차원인 데이터를 2차원으로 축소 >> 시각화 >> 데이터 경향 파악)

  차원축소 주요 기법
  - 주성분 분석(PCA : principle component analysis)
  - t-SNE

* 이상 탐지 : 이상값은 보통 데이터 분포가 매우 치우친 클래스이기 때문에,
          지도학습을 하게되면 이상값의 특징을 미처 학습하지도 못하고
          모든값에 정상이라고 분류해도 정확도가 99%가 될수있음 (imbalanced data 불균형 데이터 문제)
          그래서 이상탐지에는 비지도학습기법을 주로 사용함
          (사이킷런의 One Class SVM 사용 가능)

* 패턴 마이닝 : 데이터에서 자주 발견되는 패턴 추출 기법
          기법
          - association rule 연관법칙: a priori 알고리즘 사용
          - ARIMA(자기회귀 이동평균 모델)알고리즘 : 시계열 분석에 주로 사용

* 강화학습 : 정답 불명확 환경에서 목적을 위해 취할 행동 선택, 시행착오 거치며, 승리에 도움되면 보상, 그렇지 않으면 패널티 부가하는 식으로 행동정책 학습

============================================

=========================================
<Chapter 3 : 학습 결과 평가하기>
<평가하기>
* 평가 4가지 지표
  - 정확도 accuracy
  - 정밀도 precision
  - 재현율 recall
  - F-점수 F-measure

* confusion matrix
  TP : true positive
  TN : true negative
  FP : false positive
  FN : false negative

              |   예측결과  |
              | 양성 | 음성 |
  | 실제 | 양성 |  TP   FN
  | 결과 | 음성 |  FP   TN


  <정확도 accuracy>
    (TP + TN) / (TP + FP + TN + FN) : 정답과 일치한 수 / 전체 데이터 수
  <정밀도 precision>
    TP / (TP + FP) : 모든 output_true 중 정답맞춘_true 개수
  <재현율 recall>
    TP / (TP + FN) : 모든 정답_true 중 정답맞춘_true
  <F-점수 F-measure>
    정밀도와 재현율의 조화평균 : 점수가 높을수록 재현율과 정밀도가 고르게 높다는 의미

* 다중 클래스 분류의 평가 평균 구하기
    만약 세개의 클래스 분류라면 TP1 FP1 TP2 FP2 TP3 FP3 이 생김
  - 정밀도 마이크로 평균 : (TP1 + TP2 + TP3) / (TP1 + TP2 + TP3 + FP1 + FP2 + FP3)
  - 정밀도 매크로 평균 : (정밀도1 + 정밀도2 + 정밀도3) / 3
    (매크로 평균은 전체 성능 양상을 알기에 적합)

* 모델 성능 비교시, 데이터 분포 차이가 있는 경우 주로 F-점수 사용
  실제 문제는 정밀도와 재현율 중 무엇을 중시할지 고려하여 최소한의 성능을 보장하는 방향으로 튜닝 할것

  ex: '정밀도가 0.9미만인 모델은 채택하지 않는다'라면 > 정밀도를 먼저 0.9로 최소 조건 만족시키고 > 그 조건 만족하면서 F-점수가 높아지도록 파라미터튜닝

* 그 외에
  - ROC곡선
  - AUC 등을 평가 지표로 쓰기도 함

* !!! 모델성능평가는 비즈니스에 적용할 품질 최소 기준이라 생각하기
  모델 성능 튜닝에 너무 몰두하다보면 그 자체가 목적이 되기 쉬움!!!
  < 학습 모델 성능 != 비즈니스 목적 달성 > 별개문제임
  모델을 사용하는 목적이 무엇인지 항상 상기하기!

============= 그 외 평가법 =================
* 회귀 모델 평가
  - RMSE root mean squared error
  - 결정 계수 coefficient of determination

* A/B 테스트
  다양한 방식의 모델 프로토타입을 만든뒤, 동시에 사용자에게 사용하게 하여 더 좋은 평가를 받은 것을 채택하는 것
  (ex: 같은 웹사이트에 버튼 색깔, 버튼 문구 를 다르게 랜덤으로 사람들에 보여준뒤 어떤 색깔, 어떤 문구일때 더 반응이 좋았는지 보는 것)


=========================================
<Chapter 4 : 기존 시스템에 머신러닝 통합하기>

* 배치학습 <=> 온라인학습
  배치 batch 학습 = 일괄학습 (많은 데이터를 한번에 처리)
  온라인학습 = 순차학습 = 실시간학습 (데이터를 1건씩 순서대로 처리)

  결국 차이는
  학습 도중 최적화하는 방법 차이,
  한번에 다루는 데이터 덩어리 크기의 차이

  * 미니배치학습 mini-batch training : 일괄 학습과 순차 학습의 절충, 일정규모 데이터 샘플링하여 그룹 만들고, 그룹에 속하는 데이터를 일괄 학습 수행 > 이것을 반복
    - 예) 일반적으로 텐서플로우 모델 학습시킬때, 한번에 그 수많은 트레이닝 데이터를 다 읽지 못하니까
    데이터 300만개중, 100만개씩 나눠서 3번 순차적으로 학습시키는 것을 의미하는 듯함
    그렇게 총 300만개 데이터를 한 바퀴 돌아야 1에포크 되는 것?

* 어플리케이션과 통합 설계 방식
  1- 배치처리로 학습 + 예측결과를 어플리케이션에서 직접 산출(예측을 실시간 처리)
  2- 배치처리로 학습 + 예측결과를 API를 통해 사용(예측을 실시간 처리)
  3- 배치처리로 학습 + 예측결과를 DB에 저장하고 사용(예측을 배치 처리)
  4- 실시간 처리로 학습

  보통 모델을 학습시켜서 W가중치 값들을 저장해놓고(배치로 미리 학습해놓은 모델 확보)
  그 모델 기능만 응답해주는 API 서버를 따로 만들어서
  웹어플리케이션에서 필요할때만 API 호출보내는게 2번 방식

  1번은 어플리케이션 안에 내부적으로 모델을 넣어놓는것

  3번은 유저가 잘 쓰지 않는 새벽시간대에 한번씩 데이터로 모델을 학습시키고 미리 예측값들을 따로 DB에 저장해 놓은뒤
  어플리케이션이 필요할때 DB에서 그 값을 꺼내 사용하는것

* 머신러닝 언어와 어플리케이션 프레임워크 언어를 일치시키는게 좋지만
  어플리케이션은 Node.js, 모델은 python이라면
  모델을 임포트/익스포트할 수 있야함
  아님 Node.js로 모델을 직접 구현하든지...(머신러닝 라이브러리는 디버깅이 어려운 프로그램이라 구현 힘듬)

<로그 설계>

* 데이터 정보는 크게 3개로 나뉨
  1. 사용자 정보 : 성별, 나이 등등(서비스 가입자 정보)
  2. 콘텐츠 정보 : 상품 범주, 상품 세부 정보, 가격, 색깔 등
  3. 사용자 행동 로그 : 어떤 페이지에 접속했는지, 구매 이벤트 발생 등 (광고 클릭이 어떻게 구매로 이어졌는지)

* 1,2번 사용자정보와 콘텐츠정보는 RDBMS에 저장
  3번 사용자행동로그는 데이터양이 많기 때문에 분산RDBMS, 하둡파일시스템 등에 저장

  로그데이터는
  - 분산 RDBMS 혹은 하둡 분산파일시스템 혹은 객체 저장소에 저장(데이터 양이 많기 떄문에)
  - SQL 질의가 가능하도록 해놓을것(필요 데이터 정보를 뽑아내고 전달하는 과정이 쉬워지도록)

  * 대규모 데이터를 전송하는 비용 고려하기
  대규모 데이터를 사용하는 머신러닝에서 가장 큰 병목은 데이터 전송시간임
  가능한 데이터를 로컬 머신으로 내려받지 않을 수단 마련해야함
  데이터 전처리를 가능한 분산 RDBMS에서 SQL로 수행하는 것이 바람직


* 로그 설계시 주의사항
  - 로그에는 가능한 다양한 정보를 포함하는 것이 좋다. (후에 추가히가 힘듬)
    성별 ,방문시간대, 광고 유형 등등

  - 훈련 데이터로 만들수있는지 미리 살피기
    광고 표출 로그가 너무 많다는 이유로 저장안하고
    광고 클릭 로그만 수집하면
    표출된 광고가 클릭되지 않은 건은 알수없어서
    클릭 예측 훈련데이터 못 만듬

  - 데이터 변경 이력 저장해두기
    콘텐츠 설명문과 매상의 관계 파악에서
    만약 콘텐츠 설명문을 변경한적이 있다면
    어떤 설명문을 어떤 기간동안 사용했는지 알아야 충분히 조사 가능

  - 로그 포맷 변경도 주의하기



=========================================
<Chapter 5 : 학습 데이터 수집하기>

* feature 찾기 : 보통 heuristic 방법으로 찾음 (발견법)
  - 서비스 도중 발생하는 로그를 사용 (완전 자동)
  - 콘텐츠를 사람이 직접 보며 부여 (수동)
  - 기게적으로 정보를 부여한 뒤 사람이 확인 (자동 + 수동)

* 방법들
  1. 공개된 데이터 셋이나 모델 활용
  2. 개발자가 직접 데이터 만듬
  3. 동료나 친구에게 데이터 입력 부탁
  4. 크라우드소싱 활용
  5. 서비스(어플리케이션)에 수집기능을 넣고, 유저 입력을 활용


<1. 웹상에 공개된 데이터 셋이나 모델 활용>
    주의할점 :
    - 모델이나 데이터셋의 라이선스가 상업적 이용을 허용하는가?
    - 원하는 분야에 적용 가능 한가? : 바로 사용 못하고 가공해야할 수도 있음 (반지도학습 semi-supervised learning, 전이학습 transfer learning)

<2. 개발자가 직접 데이터 만듬>
    * 특정문제가 사람이 직접 풀기 힘들면 머신도 풀기 힘듬
    카테고리 분류가 애매한 데이터가 있다면, 고민 (새 카테고리를 만드느냐, 두 카테고리에 모두 포함되게 만드느냐 등등)
    데이터 만들면서 생기는 인사이트 활용하기(ex: 기사제목에 포함된 단어로 카테고리 분류하면 효과적이다)
    분류기준이나 분류 어려운 콘텐츠는 따로 정리해두어야함
    혼자 데이터 만드는 작업하면 편견이 개입될수 있다 (여러명이 참여하는 식으로 보완)

<3. 동료나 친구에게 데이터 입력 부탁>
    중복작업 위험 주의(레이블링 어노테이션 툴, 협업 툴 사용하기)
    데이터 분류 기준 문서화하기 (데이터 포맷이나 레이블 방향성 일치하도록)

<4. 크라우드소싱 활용>
    데이터 만드는 작업을 마이크로태스크로 작고 단순하게 만들어, 불특정 다수 사람에게 부탁하는 것

    * 특징
    - 전문가를 고용하는 것보다 작업이 빠르고, 비용이 낮음
    - 작업속도가 빠르지만, 그만큼 시행착오 여러번 반복할 수도 있음
    - 비용이 낮으므로 여러 사람에게 같은 일을 맡겨 중복작업 가능성 있음

    * 주의할점
    - 작업자가 단시간에 끝낼 수 있어야 하므로 작업을 설계하기 까다로움
    - 높은 전문선이 요구되는 작업은 절차를 잘 세분화해서 자세히 설명해야함
    - 작업 결과의 품질을 높이려면 결과를 주의해서 가공해야함

    * 팁
    - 같은 작업을 여럿에게 맡긴뒤 중복 데이터 레이블의 최종안을 다수결로 최종 결정
    - 미리 연습문제를 풀게하거나 설문조사를 통해 작업자를 걸러내기
    - 데이터 품질 평가 방법 고려하기

<5. 서비스(어플리케이션)에 수집기능을 넣고, 유저 입력을 활용>
    크라우드소싱과 비슷

    * 예시
    - 유저에게 간단한 설문조사 실시
    - 유저가 콘텐츠에 태그를 부여할수 있게 기능 추가
    - 부적절한 서비스 결과를 신고할 수 있게 하는 기능 추가

    * 주의할점
    - 이용자 수 일정규모 이상이어야함
    - 참여자에게 줄 보상 설계해야함



=========================================
<Chapter 6 : 효과 검증하기>

의도한 효과가 맞는가? 어느정도 효과가 생겼는가?

검증 : 어떤 측정값에 기초한 판단
효과 검증 : 사건 Y가 X의 영향을 얼마나 받았는지 밝히는 활동

* 효과 검증 단계 : 문제정의 > 가설설정> 개입 > 효과검증
    1.문제정의 : 유저 체류 비율을 높이고 싶다
    2.가설설정 : 추천시스템으로 추천콘텐츠를 추천하여 유저 체류시간 늘림
    3.개입(개발) : 콘텐츠 추천시스템을 개발, 적용
    4.효과검증 : 평균 체류시간이 늘었는지 확인한다

    혹은 광고에 의해 매출이 올라갔는가?

* 모델 예측 정확도 != 비즈니스 수익률
  여기서 우리가 알고싶은것은 비즈니스 수익률
  (넷플릭스 추천시스템이 이뤄넨 사업적가치로 유저 해지율 저하를 사용 : 1년에 약 10억달러의 효과 있었음 )

* 오염된 로그:
  운영중인 모델이 사용자 행동 로그를 훈련데이터로 사용한다면
  사용자의 선택이 추천시스템에 영향을 주기때문에 편향될 수 있음 (추천한걸 선택하니까, 그 선택이 로그로 남고, 그걸 모델이 학습하니까 또 비슷한내용이 추천되는 순환)

* 가설 검정 hypothesis testing : 표본(sample)을 통해 모집단에 유의한 차이가 발생했는지를 확인하는 기법
    - 귀무가설 null hypothesis:
    - 대립가설 alternative hypothesis:
    - P-value :
    - 유의수준 significant level:
