<Machine learning at work 머신러닝 실무 프로젝트 - 아리가 미치아키 - 한빛미디어>

* 모델:
  - 인풋데이터, 아웃풋 데이터 사이에 드러나지 않은 관계를
  수식, 규칙으로 근사한것
  - 알고리즘과 파라미터로 구성됨

* 인풋데이터 : 주로 벡터화(여러가지 데이터를 한 배열에 넣은 모양)

* 머신러닝 프로젝트 과정 (대체로):
  1. 문제 정의 - 목적이 무엇인지 명확히!
  2. 머신러닝을 사용하지 않는 방법 없는지 검토!!! - 기술부채(출시를 서두르기 위해 해결하지 못한 문제, 어설픈 설계, 문서화, 컴파일러 경고 등) 쉽게 누적 때문
    : 해결하려는 문제를 머신러닝 문제로 바꾸기

  3. 머신러닝 시스템을 설계
  4. 사용할 알고리즘 선택
  5. 특징과 정답 데이터, 로그를 설계 ???
  6. 데이터 수집과 전처리
    : 문제 풀기 위한 도구 선택 및 전처리

  7. 학습 수행, 파라미터 튜닝
    : 모델 구축

  8. 시스템에 통합
    : 기존 서비스에 통합

* 해결하려는 문제 자체가 사람도 하기 어려운 일이라면 머신러닝으로 해결하는 것 역시 어렵다
  (특히 지도학습, 정답이 무엇인지 사람이 기계에게 알려줘야함)


* 머신러닝 문제 해결 사례 핵심
  - 알고리즘: 어떤 알고리즘 사용?
  - 데이터특징: 어떤 데이터를 특징으로 사용?
  - 통합: 머신러닝 부분 어떻게 통합?

* 머신러닝으로 해결 가능한가? 아닌가? 구분!
  모델 구현하는 일(데이터 분석의 80%는 전처리)
  머신러닝 시스템 개발은 시행착오를 반복하는 과정
  4~7번 반복, 그러므로 시행착오 효율적으로 하는 것 중요

  ===============
<머신러닝 시스템 프로젝트 과정>

@1. 문제 정의 - 목적이 무엇인지 명확히!

@2. 머신러닝을 사용하지 않는 방법 없는지 검토!!!

    - 기술부채(출시를 서두르기 위해 해결하지 못한 문제, 어설픈 설계, 문서화, 컴파일러 경고 등) 쉽게 누적 때문

    오랜 운용 > 사용자 경향 변함 > 입력 경향 바뀜 (데이터 옥동자라는 의미 변화 예시)
    그러므로 데이터 모델도 갱신(유지보수 필요)

    애초에 머신러닝은 대량 데이터 처리에 사용되므로
    생각하지 못한 예측 결과 출력 위험 항상 존재
    (구글 포토 : 흑인을 고릴라로 인식 > 인종차별 문제 사례)

    * 2가지 조건 만족 할때 머신러닝 적용 하면 좋음
      1. 대량의 데이터에 대해 고속으로 안정된 판단 내려야한다
      2. 예측 결과에 일정 수준 오류가 용인 된다 : 예측이 100% 정확하지 않음 > 운영 쪽에서 이 오류 대응할 구조 꼭 필요
        (의도치 않은 예측결과 나오면 사후 개입하는: 고릴라같은 아웃풋은 삭제하는 룰베이스 예외처리!)

    * 최소기능제품 만들기 (MVP : minimum viable product) == 가설 검증
      : 처음 세운 가설 맞는지 미리 검증! (모델 구현 테스트 후 목표자체가 틀릴수도 있으니까)


@3. 머신러닝 시스템을 설계

    * 핵심
    1. 예측결과 어떻게 이용 : 배치 후 디비저장(따로 새벽에 모델 돌려서 예측값 얻어놓기) /혹은/ 실시간 비동기로 활용(유저 액션에 따라 바로바로 예측하기)
    2. 예측 오류의 영향을 어떻게 흡수 : 예측후 사람이 사후 체크 프로세스 만들기! /혹은/ 잘못된예측이 큰 영향 없을때 사용

    * 구체적인 목표 성능과 포기 지점 설정하기
    - 없으면 전처리 하면서 데이터 도메인 지식 생겨서... 근거없는 자신감으로 성능 계속 더 개선할 수있다는 착각의 늪 빠짐 > 매몰비용 높아짐
    (2개월 안에 90% 성능! 과같이 구체적으로 계획하기)


@4. 사용할 알고리즘 선택

    - 데이터 특성을 아느냐 : 정답을 안다면(지도학습) : 모른다면 군집화같은(비지도학습) 혹은 데이터 시각화를 통해 특징 알아내기
    - 데이터 양 : 온라인 학습 /혹은/ 배치 학습

@5. 특징과 정답 데이터, (로그를 설계: 어플리케이션 case)

    - 피쳐(특징): 어떤 피쳐를 사용할 것인가? : 도메인 전문가 협조 필요
    - 범주형 변수를 > dummy더미 변수로(원핫인코딩, 0,1수치데이터화)
    - numeric(수치형)변수는 그대로 사용 가능

    고전 머신러닝은 어떤 피쳐 선택하느냐가 핵심이었음 > 딥러닝에선 피쳐보단 신경망 구조가 핵심

    - 데이터 레이블링(정답지 만들기)
    - 웹 어플리케이션의 로그로 정답 데이터 만듬 (어떤 페이지 클릭! 광고 효과 예시)
    (로그 설계시 생각나는 특징 모두 포함 시켜야함! 로그 수집 한번 시작하면 바꾸기 어려움, 바꿔도 그전 데이터 사용 못하게됨)


@6. 데이터 수집과 전처리
    - 정상범주 넘어간 이상값 처리
    - 값의 변동폭으로 인한 영향 줄이는 정규화
    - 범주형데이터 > 수치형데이터로 변환
    등등


@7. 학습 수행, 파라미터 튜닝
    - 하이퍼 파라미터 조정하며 > 시행착오 거치기 > 더 나은 성능 찾기 (예측한 성능 기준치를 넘는 것을 목표로 하기! 목표없는성능개선X!)

    *(처음 작성한 코드가 오류없이 작동할때 느끼는 불안감 == 첫번째 예측모델에서 99% 성능이 나올때): 뭔가 의심해야함
    - 과적합 (학습데이터에만 적합, 새 데이터는 예측 못함) <=> 일반화 generalization(처음보는 데이터 처리 잘함)
    - 학습데이터에 테스트데이터 섞이는 (데이터 유출 data leakage)
    일 수 있음

    * 오답낸 예측 결과를 살펴봄 > 원인 무엇인지? 오답 공통점 없는지?
    (만약, 결과 계속 안좋다면 4단계 알고리즘 검토부터 다시)

    * 과적합 방지
    1. 교차검증 cross validation : 학습데이터를 training훈련, validation검증 (9:1)로 나눠서
      검증데이터로 성능을 그때그때 측정해가며 학습시키기

    (- 학습데이터 = (트레이닝데이터 + 검증데이터)
    - 총 데이터 = 학습데이터 + 테스트데이터)

    2. 규제화 regularization : 약간 성능 낮춰서 더 일반화 시키기 (드랍아웃처럼)
    3. 학습곡선 살피기 : learning curve



@8. 시스템에 통합
    - 예측 성능이 > 비즈니스 성과(목표) 달성하는 지 여부 모니터링
    - 데이터 경향 변함 > 그러므로 모델도 꾸준히 개선 필요 (시스템 통합하면 끝 X)
====================
<머신러닝 시스템 문제 대처>

* 머신러닝 시스템 운영 문제
A. 확률적인 부분 있어서 자동 테스트 어려움
B. 오래 운용하면 사용자 경향 변해서 입력 경향도 변함
C. 처리 파이프라인이 복잡해짐
D. 데이터 의존 관계가 복잡헤짐
E. 실험 코드 혹은 파라미터가 포함되기 쉬움
F. 개발 시스템과 운영 시스템 간의 언어/프레임워크가 제각기이기 쉽다

* 문제 대처법
1. 황금기준을 사용한 예측 성능 모니터링 (A, B, D) : 예측 성능에 임계값 알림 설정하기(일정성능 안나오면 알람)
2. 예측 모델 모듈화, 모델에 대한 A/B 테스트 실시 (B) : 예측 모델 병렬로 두고 바꿔가며 성능 테스트
3. 모델 버전관리 > 원하는 모델로 돌아가기 가능하도록 (D, E) : 자유로운 롤백 (소스코드, 모델, 데이터 모두 버전관리 하기)
4. 데이터 처리 파이프라인 자체를 저장 (C, E) : 전처리 과정 코드도 모델과 함께 저장하기 (자연어처리시 단어 분절, 단어 빈도 측정의 전처리 단계에서도 파라미터튜닝이 존재하기 때문)
5. 개발 시스템과 운영 시스템 간의 언어/프레임워크 일치시키기 (F) : 파이썬 텐서플로우 모델 + 파이썬 장고 웹 프레임워크, 그래야 마이그레이션과 커뮤니케이션 비용 줄임 /혹은/ REST API서버화(마이크로 서비스)

* 딥러닝 부상 전의 머신러닝 사실상 표준은 : 사이킷런

=================

<머신러닝 시스템 성공적 운영>

* 일반 시스템 개발과는 달리
머신러닝 시스템은 개발해도 결과물이 안나올수도 있음!!!
(ㅋㅋㅋ 삼성해커톤 소음예측모델개발 경험 ㅋㅋㅋ 어려우면 다른 방식으로라도 만드는 웹어플개발과 다름... 모델 학습이 안되면 쓸수가 없고 다른방법이 없음)

* 키 리소스(인력)
  1. 도메인 전문가 (도메인)
  2. 통계(수학), 머신러닝 전문가 (데이터 사이언티스트) : 문제 설정하는 의사소통 능력 필수
  3. 데이터 분석 인프라 구축 가능한 엔지니어 (컴퓨터 사이언스)
  4. 실패에 대한 위험을 짊어질 수 있는 책임자 : 머신러닝 프로젝트는 실패 확률이 높은 투자임! 머신러닝으로 가치를 얻기를 설득할수 있는 사람! 실무자가 실무에 집중할수있게!
  (4번은 처음 알았다!!!)


===================
<정리 >
< 머신러닝 프로젝트 진행할때는 >
1. MVP로 개념 검증 최우선
2. 머신러닝 이외 해결 방법 꼭 찾아보기!!!
3. 머신러닝에 적합한 문제인지 파악
4. 예측 성능 과 비즈니스 성과!!! 모두 충족시키는지 모니터링


===================
내 머신러인 프로젝트 실패 경험이 정말 값진거였다는걸 깨달았다
1. 후후앤컴퍼니 스팸지수예측 프로젝트와
2. 삼성AI해커톤 소음예측 노이즈캔슬링 프로젝트
모두 머신러닝 만능설 같은 내 고정관념을 깨주었고
웹어플 개발과는 다르게 결과물이 안나올수도 있다는 걸 알려줬고
무엇보다 성능이 먼저 검증이 안되면 시작하면 안된다는 교훈을 주었다
머신러닝 시스템 자체가 실패 가능성이 높은 시스템이라는 사실!!!
===================

<머신러닝 알고리즘 종류>
1. 분류 : 정답이 카테고리
2. 회귀 : 정답이 수치
3. 군집화 : 데이터 그룹화
4. 차원 축소 : 시각화 /혹은/ 계산량 절감
5. 그 외 :
  - 추천
  - 이상 탐지 : 평소와 다른 행동 검출
  - 고빈도 패턴 마이닝 : 발생 빈도 높은 패턴 추출 (기저기와 맥주 사례)
  - 강화학습 : 정답 불명확 환경에서 취할 행동 선택


* 알고리즘 선택 프로세스
데이터가 충분한가(수집) > 범주를 예측하는가(수치 예측) > 정답에 레이블이 있는가(없는가) >


* 분류:
  - 퍼셉트론
  - 로지스틱 회귀
  - 서포트 벡터 머신(SVM)
  - 신경망
  - K-NN(최근접이웃)
  - 결정트리
  - 랜덤포레스트
  - 경사부스팅 결정트리(GBDT)

  그외)
  - 나이브 베이즈 Naive Bayes : 텍스트분류에 사용
  - HMM 히든 마코프 모델 : 음성인식에서 사용

<참고 사항>
  *온라인 학습 : 최적화 하는 방식이 데이터를 하나씩 입력 : 예) 퍼셉트론
   배치 학습  : 최적화 하는 방식이 데이터를 한꺼번에 입력

  *선형분리 (linearly separable) : 무조건 직선으로 나눠짐(직선이 아니라 곡선이라면 X)

  *계단함수step function : 옛날에 쓰던 활성함수 (입력값을 +1 또는 -1로만 바꿔줌)

<퍼셉트론 특성>
    온라인 학습방식
    예측 성능 보통, 학습 빠름
    과적합되기 쉬움
    선형분리 가능한 문제만 풀수있음

    hinge loss 힌지 손실 사용 (렐루 반대모양 )
    SGD stochastic gradient descent 확률적경사하강법 을 사용해 W가중치백터(파라미터) 최적화 함
    활성함수로 계단함수 사용

<로지스틱 회귀>
    출력뿐만 아니라 출력값에 해당하는 속할 '확률'을 계산 가능
    온라인 학습, 배치 학습 모두 가능
    예측 성능 보통, 학습 속도 빠름
    과적합 방지하는 규제항 추가되어있음
    결정경계가 직선이기 때문에 선형 분리 가능한 문제만 풀수있음

    활성함수로 sigmoid, cross-entropy error function 사용

<서포트벡터머신>
    선형분리가 불가능하는 문제에도 적용가능
    마진 최대화를 통해 매끈한 초평면을 학습할 수 있다
    커널이라는 방법을 이용하여 비선형 데이터를 분리할수있다
    선형 커널로는 차원수가 높은 희소sparse 데이터도 학습할수있다
    배치 학습과 온라인 학습에 모두 적용할 수 있다

    * 서포트벡터 : 초평면으로부터(두 집단 경계) 가장 가까운 각 클래스의 데이터
    힌지 손실 가로축 교점이 다름 (0이 아니고 y = 1이 교점)
    이것 때문에 결정경계에 아슬아슬하게 걸처 정답이 된 데이터도 약하게 패널티가 부가되어 결정경계에 마진이 생김
    마진 최대화 생김

    * 두가지 특성
    이렇게 마진 최대화가 : 과적합 억제효과 생김
    커널 기법 : 선형분리가 불가능한 데이터 차원수를 늘려서 선형분리가 가능하게 만듬

    선형커널, 다항식 커널, RBF커널, 등 존재

<신경망>
    다층퍼셉트론

    비선형 데이터를 분리 가능(퍼셉트론과 차이)
    학습 시간이 오래 걸림(GPU기술 발전으로 해결)
    파라미터 수가 많으므로 과적합을 일으키기 쉬움
    가중치의 초기값에 민감하여, 로컬 최적점에 빠지기 쉬움

    softmax함수 사용
    활성함수로 ReLU 함수 사용
    학습에 backpropagation 사용

<k-NN>
    새로 입력된 데이터 > 가장 가까운 k개의 데이터 선택 > k개의 데이터의 다수결 결정(3개 선택중 AAB 라면 A가 2개로 더 많으니까 새 데이터도 A로 판별)

    데이터를 하나씩 순차적으로 학습
    기본적으로 모든 데이터와의 거리를 계산해야 하므로 예측 시간이 걸린다
    k값에 따라 편차는 있지만 예측 성능은 쵄찮은 편이다
    정규화를 통해 피처들끼리의 스케일을 맞출필요가 있다(피처 (예:x,y)축마다 스케일 차이가 있으면 학습이 제대로 되지 않음)

    거리는 유클리드 거리, 마할라노비스 거리를 사용하기도 한다
